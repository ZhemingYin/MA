# Macros
# ==============================================================================
frame_length = 4
sampling_rate = 2
# batch_size = 8
ckpt_max_to_keep = 5
num_samples = 512
num_chirps = 64
whether_fftshift = True
processing_method = 'padding&shuffle&ap/ph&with_log10&abs_normalization(0,1)&no_angle_normalization'     # The type of pre- or post-processing, format {processing type: padding or conv or no_processing}&{upsampling type: shuffle or transposed}&{separation type: re/im or ap/ph or ap}&{with_log10, with_log2 or no_log}&{abs normalization type:abs_normalization(0,1) or abs_normalization(-1,1) or no_abs_normalization}&{angle normalization type: angle_normalization or no_angle_normalization}
vgg_layer_names = ['block1_conv2', 'block2_conv2', 'block3_conv4', 'block4_conv4']


# Paths in remote server
# ==============================================================================
sd_dataset.base_dir = '/data/public/rd_sr/dataset_2/'
sd_dataset.tfrecord_folder = '/no_backups/d1513/tfrecord/'   # the folder to save tfrecord files
main.checkpoint_path = '/no_backups/d1513/checkpoints/'    # the folder to save checkpoints
Evaluation.checkpoint_restore_path = '/no_backups/d1513/checkpoints/ckpt_CNN_simple/train_2024_10_31_11_3_38/'    # the folder to restore the checkpoint
Evaluation.benchmark_checkpoint_path = '/no_backups/d1513/checkpoints/ckpt_CNN_simple/train_2024_10_31_11_3_38/'    # the folder to restore the benchmark checkpoint


# # Paths in local computer
# # ==============================================================================
# sd_dataset.base_dir = '/Users/yinzheming/Downloads/MA/dataset/dataset_2/'
# sd_dataset.tfrecord_folder = '/Users/yinzheming/Downloads/MA/tfrecord/'   # the folder to save tfrecord files
# main.checkpoint_path = '/Users/yinzheming/Downloads/MA/checkpoints/'    # the folder to save checkpoints
# Evaluation.checkpoint_restore_path = '/Users/yinzheming/Downloads/MA/checkpoints/ckpt_UNet_concat/Train_2024_11_18_23_32_16/'    # the folder to restore the checkpoint
# Evaluation.benchmark_checkpoint_path = 'None'    # if benchmark model name is interpolation, here doesn't matter


# General settings for main file
# ==============================================================================
# main.create_tfrecords = False    # bool, whether to create tfrecords, if True, the tfrecords files will be created
main.type = 'Tune'    # the type of the process, options: 'Train', 'Test', 'Tune'
main.model_name = 'DP-Transformer'    # the name of the model to be trained


# Loading dataset
# ==============================================================================
sd_dataset.train_types = ['corridor&slow_tempo', 'corridor&medium_tempo']      # Format {env}&{tempo}, options for envs: 'corridor'; options for tempos: 'slow_tempo', 'medium_tempo'
sd_dataset.test_types = ['corridor&medium_tempo']      # Format {env}&{tempo}, options for envs: 'corridor'; options for tempos: 'slow_tempo', 'medium_tempo'
sd_dataset.shift_window = %frame_length    # shift window for augmenting the dynamic dataset
sd_dataset.frame_length = %frame_length     # the number of frames as input, including the current frame and the past frames
sd_dataset.sampling_rate = %sampling_rate    # the sampling rate of the range_doppler map
sd_dataset.train_test_ratio = 0.8    # the ratio of the train dataset if both train and test need the same type of dataset
sd_dataset.random_state = 42    # the random seed for splitting the dataset
sd_dataset.static_remove_duplicates = True    # whether to remove the duplicated or similar data for static type
sd_dataset.low_res_processing_type = 'voltage'   # the unit of the low resolution data, options: 'voltage', 'power', 'dBW' and 'dBm'
sd_dataset.high_res_processing_type = 'voltage'   # the unit of the high resolution data, options: 'voltage', 'power', 'dBW' and 'dBm'
sd_dataset.is_high_pass_filter = False    # whether to use high pass filter for the data


# Prepare the dataset
# ==============================================================================
prepare.buffer_size = 50    # the buffer size for shuffling the dataset
prepare.shuffle_seed = 42   # the random seed for shuffling the dataset
prepare.batch_size = %batch_size    # the batch size for training


# Data processing
# ==============================================================================
processing.R = 50    # the resistance of the radar
processing.data_size_info = [%frame_length, %sampling_rate, %num_samples, %num_chirps]
plot_range_doppler.R = 50    # the resistance of the radar
rD_processing.whether_fftshift = %whether_fftshift    # whether to use fftshift for the range_doppler map
resampling_processing.resampling_factor = %sampling_rate
resampling_processing.num_chirps = %num_chirps
resampling_processing.num_samples = %num_samples


# Train
# ==============================================================================
# Trainer.epochs = 200    # the number of epochs for training
# Trainer.learning_rate = 1e-5    # the learning rate for training
Trainer.ckpt_max_to_keep = %ckpt_max_to_keep    # the maximum number of checkpoints to keep
# Trainer.optimizer_type = 'Adam'   # the type of optimizer for training
Trainer.early_stop_patience = 10     # After the value of patience epochs, if no better loss, the training will be stopped
Trainer.loss_type = 'lsd&frequency_domain'   # Format {loss_function_type}&{data_type}, options for the first {}: 'lsd', 'perceptual', 'mse', 'sd_sdr', 'sdr'; options for the second {}: 'time_domain' or 'frequency_domain'
Trainer.early_stop_type = True  # whether to use early stop
Trainer.lr_schedule_type = True    # whether to use learning rate schedule
Trainer.overfitting_type = False    # whether to use overfitting training without validation
Trainer.pretraining = True
Trainer.layer_names = %vgg_layer_names
Trainer.lambda_lsd = 1.0
Trainer.lambda_vgg = 0.5
Trainer.lambda_disc = 0.0
Trainer.processing_method = %processing_method

# Loss function
# ==============================================================================
lsd.scaling_factor = 1
lsd.thres_type = 'batch_median'
lsd.processing_method = %processing_method

generator_loss.LAMBDA_l1_loss = 1.0
generator_loss.LAMBDA_perceptual_loss = 1e-2
generator_loss.LAMBDA_gan_loss = 1e-5

convert_to_time_domain.whether_fftshift = %whether_fftshift


# Evaluation
# ==============================================================================
Evaluation.ckpt_max_to_keep = %ckpt_max_to_keep   # the maximum number of checkpoints to keep

# Calculate the resolution
resolution_calculation.start_frequency_GHz = 59   # the start frequency of the radar, unit in GHz
resolution_calculation.end_frequency_GHz = 63   # the stop frequency of the radar, unit in GHz
resolution_calculation.chirp_repetition_time_s=0.000220  # the chirp repetition time of the radar, unit in s

# DP-Transformer
# =================================================================
# DPTransformerSTFT.num_dp_layers = 1
# DPTransformerSTFT.num_layers = 1
DPTransformerSTFT.d_model = 64
# DPTransformerSTFT.dff = 64
DPTransformerSTFT.num_heads = 2
# DPTransformerSTFT.enc_kernel_size = 3
# DPTransformerSTFT.dec_kernel_size = 3
DPTransformerSTFT.enc_filters = 64
DPTransformerSTFT.dec_filters = 64
DPTransformerSTFT.sep_filters = 64
DPTransformerSTFT.maximum_position_encoding = 10000
DPTransformerSTFT.re_im_split = 0
DPTransformerSTFT.strides = 1
DPTransformerSTFT.upsampling_ratio = %sampling_rate
DPTransformerSTFT.input_size_info = [%batch_size, %sampling_rate, %frame_length, %num_samples, %num_chirps]
DPTransformerSTFT.processing_method = %processing_method